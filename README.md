# CETESB CADRI Data Extractor

Sistema automatizado para extrair dados cadastrais de empresas e informa√ß√µes t√©cnicas detalhadas de documentos CADRI (Certificados de Movimenta√ß√£o de Res√≠duos de Interesse Ambiental) do site p√∫blico da CETESB.

## üìà Evolu√ß√£o do Projeto

### Vers√£o 3.1 (Setembro 2025) - Parser LLM Integrado
- **ü§ñ Parser LLM**: Extra√ß√£o via LLM com structured outputs usando OpenRouter
- **üîÑ Modo h√≠brido**: LLM com fallback autom√°tico para regex parser
- **üìä Pydantic schemas**: Valida√ß√£o estruturada de 47 campos com type hints
- **‚öôÔ∏è M√∫ltiplos parsers**: 5 m√©todos de parsing (llm, regex, docling, auto, hybrid)
- **üéØ Alta precis√£o**: LLM adapta-se a varia√ß√µes de layout nos PDFs

### Vers√£o 3.0 (Setembro 2025) - Expans√£o Completa
- **‚ú® Extra√ß√£o expandida**: De 15 para 47 campos estruturados por item
- **üè¢ Dados das entidades**: Captura completa de informa√ß√µes de geradores e destinat√°rios
- **üìÑ Metadados do documento**: Processo, certificado, vers√£o e datas
- **üîß Novos utilit√°rios**: `cadri_utils.py`, `monitor_progress.py`
- **‚ö° Parser otimizado**: Melhor reconhecimento de padr√µes em PDFs

### Vers√£o 2.0 (Setembro 2025) - Pipeline Robusto
- **üîÑ Pipeline completo**: 4 etapas automatizadas (list ‚Üí detail ‚Üí download ‚Üí parse)
- **üì• Download direto**: Descoberta de padr√µes de URL para PDFs
- **üéØ Parser standalone**: Extra√ß√£o inicial de 15 campos t√©cnicos
- **üíæ CSV estruturado**: Persist√™ncia com deduplica√ß√£o

### Vers√£o 1.0 (Setembro 2025) - MVP
- **üåê Web scraping**: Coleta de empresas e documentos CADRI
- **üìä Estrutura b√°sica**: Dados cadastrais e t√©cnicos essenciais

## Objetivo

Gerar **duas tabelas de dados estruturadas**:

1. **üìã Dados Cadastrais** (`empresas.csv`) - Informa√ß√µes de todas as empresas listadas no site CETESB
2. **üóÇÔ∏è Dados T√©cnicos** (`cadri_itens.csv`) - Informa√ß√µes detalhadas extra√≠das dos documentos CADRI com 47 campos estruturados

## Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone <repo-url>
cd cetesb-cadri-csv

# Instale depend√™ncias
pip install -r requirements.txt

# (Opcional) Para usar parser LLM
pip install -r requirements-llm.txt

# Instale Playwright browsers
playwright install chromium

# Configure ambiente
cp .env.example .env
# Edite o .env e adicione OPENROUTER_API_KEY se quiser usar parser LLM
```

### Configura√ß√£o do Parser LLM (Opcional)

Para usar o parser baseado em LLM, voc√™ precisa:

1. **Obter uma API key do OpenRouter:**
   - Acesse [OpenRouter.ai](https://openrouter.ai)
   - Crie uma conta e gere uma API key
   - Adicione cr√©ditos √† sua conta (custo por uso)

2. **Configurar a API key no .env:**
   ```bash
   OPENROUTER_API_KEY=sk-or-v1-your-key-here
   LLM_PARSER_ENABLED=true
   LLM_DEFAULT_MODEL=cost-optimized  # ou 'flagship' para maior precis√£o
   ```

3. **Instalar depend√™ncias adicionais:**
   ```bash
   pip install -r requirements-llm.txt
   ```

## Uso Simplificado

### 1. Pipeline Completo (Coleta + Download + Parsing)

```bash
# Executar todas as etapas automaticamente
python -m src.pipeline --stage all
```

### 2. Etapas Individuais

```bash
# Etapa 1: Coletar empresas e documentos
python -m src.pipeline --stage list --seeds CEM,AGR,BIO
python -m src.pipeline --stage detail

# Etapa 2: Baixar PDFs
python cert_mov_direct_downloader.py

# Etapa 3: Extrair dados dos PDFs (regex parser)
python pdf_parser_standalone.py

# Ou usar parser LLM (requer OpenRouter API key)
python -m src.llm_pdf_parser
```

### 3. Busca por CNPJs

```bash
# Pipeline completo com lista de CNPJs
python -m src.pipeline --stage all --cnpj-file empresas.xlsx

# Apenas busca por CNPJs espec√≠ficos
python -m src.pipeline --stage list --cnpj-file lista_cnpjs.xlsx

# Combinado com outras etapas
python -m src.pipeline --stage list --cnpj-file empresas.xlsx
python -m src.pipeline --stage detail
```

### 4. M√©todos de Parsing (Novo!)

```bash
# Parser LLM com structured outputs (m√°xima precis√£o)
python -m src.pipeline --stage parse --parser-method llm

# Parser h√≠brido - LLM com fallback autom√°tico (recomendado)
python -m src.pipeline --stage all --parser-method hybrid

# Parser regex tradicional (mais r√°pido)
python -m src.pipeline --stage parse --parser-method regex

# Parser Docling avan√ßado
python -m src.pipeline --stage parse --parser-method docling

# Sele√ß√£o autom√°tica inteligente
python -m src.pipeline --stage parse --parser-method auto
```

#### Compara√ß√£o dos M√©todos de Parsing

| M√©todo | Precis√£o | Velocidade | Flexibilidade | Custo |
|--------|----------|------------|---------------|-------|
| **LLM** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | M√©dio |
| **H√≠brido** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Baixo |
| **Regex** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Gr√°tis |
| **Docling** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Gr√°tis |
| **Auto** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Vari√°vel |

##### Modelos LLM Dispon√≠veis (via OpenRouter)

O parser LLM pode usar diferentes modelos configurados no `open_router_controller.py`:
- **`cost-optimized`** (padr√£o): Google Gemini 2.5 Flash - Balan√ßo entre custo e qualidade
- **`flagship`**: Google Gemini 2.5 Pro - M√°xima precis√£o
- **`free-gemini`**: Google Gemini 2.0 Flash (gr√°tis, mas limitado)
- **`deepseek`**: DeepSeek Chat v3.1 - Alternativa de custo baixo

## Arquitetura

```
Empresas ‚Üí Documentos ‚Üí PDFs ‚Üí Dados Extra√≠dos
   ‚Üì           ‚Üì         ‚Üì         ‚Üì
List    ‚Üí   Detail  ‚Üí  Download ‚Üí Parse
```

### Componentes Principais

#### üîß Core Pipeline
- **`src/pipeline.py`**: Orquestrador principal com 4 etapas (list, detail, download, parse)
- **`src/scrape_list.py`**: Coleta empresas via Playwright (seeds + CNPJs)
- **`src/scrape_detail.py`**: Extrai documentos CADRI via httpx
- **`src/store_csv.py`**: Persist√™ncia CSV com schema de 47 campos
- **`src/cnpj_loader.py`**: Carregamento e valida√ß√£o de CNPJs via XLSX

#### üì• M√≥dulos de Download
- **`cert_mov_direct_downloader.py`**: Download direto otimizado com descoberta de URL patterns
- **`interactive_pdf_downloader.py`**: Fallback interativo com Playwright para casos especiais
- **`src/pdf_url_builder.py`**: Constru√ß√£o inteligente de URLs de PDFs

#### üìä Parser e An√°lise
- **`pdf_parser_standalone.py`**: Extrator regex avan√ßado com 47 campos estruturados
  - Extra√ß√£o de dados das entidades (geradora/destina√ß√£o)
  - Parsing de caracter√≠sticas t√©cnicas dos res√≠duos
  - Captura de metadados do documento
- **`src/llm_pdf_parser.py`**: Parser LLM com structured outputs
  - Usa OpenRouter API para extra√ß√£o via LLM
  - Structured outputs com valida√ß√£o Pydantic
  - Fallback autom√°tico para regex parser
- **`src/schemas.py`**: Schemas Pydantic para valida√ß√£o de dados
  - Modelos de dados estruturados para 47 campos
  - Type hints e valida√ß√£o autom√°tica
  - Convers√£o para formato CSV plano

#### üõ†Ô∏è Utilit√°rios
- **`monitor_progress.py`**: Dashboard de progresso em tempo real
  - Status por etapa do pipeline
  - Estat√≠sticas de extra√ß√£o
  - Identifica√ß√£o de pend√™ncias
- **`cadri_utils.py`**: Ferramentas de gerenciamento
  - Listagem de tipos de documentos
  - Valida√ß√£o de dados
  - Contagem e estat√≠sticas

## Dados Extra√≠dos

### empresas.csv (Dados Cadastrais)
- `cnpj` (chave prim√°ria)
- `razao_social`
- `logradouro`, `municipio`, `uf`, `cep`
- `numero_cadastro_cetesb`
- `descricao_atividade`

### cadri_itens.csv (Dados T√©cnicos Expandidos - 47 Campos)

**üìã Identifica√ß√£o do Res√≠duo (5 campos):**
- `numero_residuo` (D099, F001, K001, etc.)
- `descricao_residuo`
- `classe_residuo` (I, IIA, IIB)
- `estado_fisico` (LIQUIDO, SOLIDO, GASOSO)
- `item_numero` (ordem do item no documento)

**üî¨ Caracter√≠sticas T√©cnicas (7 campos):**
- `quantidade`, `unidade` (t, kg, L, m¬≥)
- `oii` (Org√¢nico/Inorg√¢nico)
- `composicao_aproximada`
- `metodo_utilizado`
- `cor_cheiro_aspecto`
- `raw_fragment` (texto original extra√≠do)

**üì¶ Log√≠stica (4 campos):**
- `acondicionamento_codigos` (E01,E04,E05)
- `acondicionamento_descricoes` (Tambor, Tanque, Bombonas)
- `destino_codigo` (T34, etc.)
- `destino_descricao`

**üè¢ Entidade Geradora (13 campos):**
- `geradora_nome` - Raz√£o social
- `geradora_cadastro_cetesb` - N√∫mero de cadastro
- `geradora_logradouro`, `geradora_numero`, `geradora_complemento`
- `geradora_bairro`, `geradora_cep`, `geradora_municipio`, `geradora_uf`
- `geradora_atividade` - Descri√ß√£o da atividade
- `geradora_bacia_hidrografica` - Bacia hidrogr√°fica
- `geradora_funcionarios` - N√∫mero de funcion√°rios

**üöõ Entidade de Destina√ß√£o (14 campos):**
- `destino_entidade_nome` - Raz√£o social do destinat√°rio
- `destino_entidade_cadastro_cetesb` - N√∫mero de cadastro
- `destino_entidade_logradouro`, `destino_entidade_numero`, `destino_entidade_complemento`
- `destino_entidade_bairro`, `destino_entidade_cep`, `destino_entidade_municipio`, `destino_entidade_uf`
- `destino_entidade_atividade` - Atividade do destinat√°rio
- `destino_entidade_bacia_hidrografica` - Bacia hidrogr√°fica
- `destino_entidade_licenca` - N√∫mero da licen√ßa ambiental
- `destino_entidade_data_licenca` - Data de emiss√£o da licen√ßa

**üìÑ Dados do Documento (8 campos):**
- `numero_documento` - N√∫mero do CADRI
- `tipo_documento` - CADRI ou Certificado
- `numero_processo` - N√∫mero do processo CETESB
- `numero_certificado` - N√∫mero do certificado
- `versao_documento` - Vers√£o do documento
- `data_documento` - Data de emiss√£o
- `data_validade` - Data de validade
- `updated_at` - Timestamp da √∫ltima atualiza√ß√£o

## Monitoramento

```bash
# Dashboard de progresso completo
python monitor_progress.py

# Estat√≠sticas detalhadas
python cadri_utils.py count         # Contagem por tipo de documento
python cadri_utils.py validate      # Valida√ß√£o de dados extra√≠dos
python cadri_utils.py list-types    # Tipos de documentos dispon√≠veis

# Verificar PDFs espec√≠ficos
python pdf_parser_standalone.py --document 16000520
python pdf_parser_standalone.py --force-reparse  # Reprocessar todos
```

## Formato do Arquivo XLSX de CNPJs

Para usar a funcionalidade de busca por CNPJs, crie um arquivo Excel (.xlsx) com a seguinte estrutura:

| cnpj |
|------|
| 11222333000181 |
| 44555666000199 |
| 77888999000155 |

**Requisitos:**
- Coluna deve se chamar exatamente "cnpj" (min√∫sculo)
- CNPJs podem ter ou n√£o formata√ß√£o (pontos/barras s√£o removidos automaticamente)
- CNPJs inv√°lidos s√£o ignorados com aviso no log
- Duplicatas s√£o automaticamente removidas

**Exemplo de uso:**
```bash
# Salvar lista de CNPJs em empresas.xlsx
python -m src.pipeline --stage all --cnpj-file empresas.xlsx
```

## Configura√ß√£o (.env)

```env
# Rate limiting (segundos)
RATE_MIN=0.6
RATE_MAX=1.4

# Browser settings
HEADLESS=true
BROWSER_TIMEOUT=30000

# Limites
MAX_PAGES=10
MAX_RETRIES=3

# LLM Parser (opcional - necess√°rio para usar parser LLM)
LLM_PARSER_ENABLED=true
LLM_DEFAULT_MODEL=cost-optimized
LLM_MAX_TEXT_LENGTH=15000
LLM_TEMPERATURE=0.1
LLM_BATCH_SIZE=100

# OpenRouter API Key (necess√°rio para parser LLM)
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

## Resultados Esperados

Com a configura√ß√£o padr√£o, o sistema extrai:
- **~5.000+ empresas** cadastradas na CETESB
- **~15.000+ documentos** CADRI dispon√≠veis
- **~50.000+ itens de res√≠duos** com informa√ß√µes t√©cnicas detalhadas
- **47 campos estruturados** por item, incluindo:
  - Dados completos da entidade geradora
  - Informa√ß√µes detalhadas do destinat√°rio
  - Metadados do processo e certificados
  - Caracter√≠sticas t√©cnicas expandidas

## Caracter√≠sticas T√©cnicas

- **üîÑ Opera√ß√µes idempotentes**: Pode ser interrompido e retomado
- **üìä Extra√ß√£o estruturada**: 47 campos t√©cnicos expandidos por item
- **ü§ñ Parser LLM**: Extra√ß√£o via IA com structured outputs (OpenRouter)
- **üîÄ M√∫ltiplos m√©todos**: 5 op√ß√µes de parsing (LLM, regex, docling, auto, h√≠brido)
- **‚úÖ Valida√ß√£o Pydantic**: Schemas estruturados com type hints
- **‚ö° Download otimizado**: URL pattern discovery para downloads diretos
- **üõ°Ô∏è Rate limiting**: Respeita limites do servidor
- **üíæ Persist√™ncia CSV**: Dados estruturados prontos para an√°lise
- **üéØ Parser inteligente**: Reconhecimento de padr√µes complexos em PDFs
- **üìà Monitoramento real-time**: Dashboard de progresso detalhado
- **‚Ü©Ô∏è Fallback autom√°tico**: Modo h√≠brido usa regex se LLM falhar

## Limita√ß√µes

1. **Sem API p√∫blica**: Sistema baseado em web scraping
2. **Dependente de layout**: Parser regex requer PDFs com padr√£o estruturado (LLM √© mais flex√≠vel)
3. **Rate limiting obrigat√≥rio**: Necess√°rio respeitar limites do servidor
4. **Stopwords corporativas**: Termos como "LTDA", "ME" n√£o retornam resultados em buscas textuais
5. **Custo do LLM**: Parser LLM requer API key do OpenRouter e tem custo por token processado

## Suporte

Para d√∫vidas ou problemas, consulte os logs em `data/scraper.log` ou abra uma issue no reposit√≥rio.

## Licen√ßa

MIT License - Veja arquivo LICENSE para detalhes.